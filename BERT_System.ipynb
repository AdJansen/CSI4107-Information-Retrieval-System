{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement an Information Retrieval (IR) system based on the vector space model, for a collection of documents\n",
    "#For weighting, you can use the tf-idf weighting scheme (wij = tfij∙idfi)\n",
    "#For each query, your system will produce a ranked list of documents, starting with the most similar to the query and ending with the least similar. For the query terms you can use a modified tf-idf weighting scheme wiq = (0.5 + 0.5 tfiq)∙idfi\n",
    "#For the ranking, you can use the cosine similarity measure\n",
    "import time\n",
    "import Porter_Stemming as ps\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import string\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import math\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1 Preprocessing\n",
    "#Input: Documents that are read one by one from the collection\n",
    "#Output: Tokens to be added to the index (vocabulary)\n",
    "#Get Start time \n",
    "start_time = time.time()\n",
    "\n",
    "coll_files = [f for f in os.listdir(r\"./coll/\") if os.path.isfile(os.path.join(r\"./coll/\", f))]\n",
    "stop_words = open(r\"./stopwords.txt\", \"r\").read().split()\n",
    "\n",
    "def collect_info(coll_files, stop_words):\n",
    "    files = {} \n",
    "    list_of_words = [] \n",
    "    bert_files = []\n",
    "    bert_docnos = []\n",
    "    vocabulary = set([]) #We use a set because we don't want to have duplicates in the vocabulary\n",
    "    total_length = len(coll_files)\n",
    "    count = 0\n",
    "    for file in coll_files: #For each file in the collection\n",
    "        count += 1\n",
    "        with open(r\"./coll/\" + file, \"r\") as f: #Open the file\n",
    "            soup = BeautifulSoup(f, 'lxml') \n",
    "            \n",
    "            for doc in soup.find_all('doc'): #For each document in the file\n",
    "                docno = doc.find_all('docno')[0].text.strip() #Get the docno\n",
    "\n",
    "                temptxt = str(doc.find('text')).replace('<text>', ' ').replace('</text>', ' ').replace('\\n', ' ').replace('\\t', ' ') #Get the text, replace the tags and new lines with spaces\n",
    "                temptxt = temptxt.lower()\n",
    "                temptxt = temptxt.translate(str.maketrans(\"'\", \" \")) #Remove apostrophes\n",
    "                temptxt = temptxt.translate(str.maketrans(\"\", \"\", string.punctuation)) #Remove punctuation\n",
    "                temptxt = temptxt.translate(str.maketrans(string.digits, \" \" * len(string.digits)))\n",
    "                \n",
    "                list_of_words = temptxt.split()\n",
    "            \n",
    "                temptxt = [word for word in list_of_words if word not in stop_words]\n",
    "                \n",
    "                porter = ps.PorterStemmer()\n",
    "                temptxt = [porter.stem(word, 0, len(word)-1) for word in temptxt]\n",
    "                \n",
    "                #temptxt = list(set(list_of_words) - set(stop_words))\n",
    "                \n",
    "                listtxt = \" \".join(temptxt)\n",
    "                \n",
    "                bert_files.append(listtxt)\n",
    "                bert_docnos.append(docno)\n",
    "                \n",
    "                vocabulary.update(set(temptxt))\n",
    "                files.update({docno: temptxt}) #We cannot check the length of the list of words because we don't know how many words are in the stop words list\n",
    "        print (\"Progress: \" + str(count) + \"/\" + str(total_length))\n",
    "    return files, vocabulary, bert_files, bert_docnos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag_map = {\n",
    "        'NN': [ wn.NOUN ],\n",
    "        'JJ': [ wn.ADJ, wn.ADJ_SAT ],\n",
    "        'RB': [ wn.ADV ],\n",
    "        'VB': [ wn.VERB ],\n",
    "        \n",
    "\n",
    "    }\n",
    "\n",
    "def expand_tokens(token_tags):\n",
    "    expanded_tokens = []\n",
    "    for i in range(len(token_tags)):\n",
    "        syns = wn.synsets(token_tags[i][0], pos_tag_map[token_tags[i][1][0:2]])\n",
    "        for syn in syns:\n",
    "            for l in syn.lemmas():\n",
    "                expanded_tokens.append(l.name())\n",
    "\n",
    "    # Remove duplicates\n",
    "    expanded_tokens = list(set(expanded_tokens))\n",
    "    refined_tokens = []\n",
    "    # Only keep tokens that are similar to multiple words in the original query using wup_similarity\n",
    "    for i in range(len(expanded_tokens)):\n",
    "        for j in range(len(token_tags)):\n",
    "            if i != j and len(wn.synsets(expanded_tokens[i])) >= 1 and len(wn.synsets(token_tags[j][0])) >= 1:\n",
    "                \n",
    "                if wn.synsets(expanded_tokens[i])[0].wup_similarity(wn.synsets(token_tags[j][0])[0]) > 0.8: #nice\n",
    "                    # If the token has an underscore, split it and append as multiple words\n",
    "                    if '_' in expanded_tokens[i]:\n",
    "                        # refined_tokens += expanded_tokens[i].lower().split('_')\n",
    "                        # break\n",
    "                        continue\n",
    "                    else:\n",
    "                        refined_tokens.append(expanded_tokens[i].lower())\n",
    "                        break\n",
    "                    \n",
    "    # Remove duplicates\n",
    "    refined_tokens = list(set(refined_tokens))\n",
    "\n",
    "    return refined_tokens\n",
    "\n",
    "def collect_queries():\n",
    "    queries = {}\n",
    "    expandos = {}\n",
    "    list_of_words = [] \n",
    "    bert_queries = []\n",
    "    \n",
    "    \n",
    "    with open(r\"./topics1-50.txt\", \"r\") as f:\n",
    "        soup = BeautifulSoup(f, 'lxml') \n",
    "        \n",
    "        for top in soup.find_all('top'):\n",
    "            num = top.find_all('num')[0].text.strip()[0:2].strip() #this is a stupid way to do it, don't follow my example \n",
    "\n",
    "            temptxt = str(top.find('title')).replace('<title>', ' ').replace('</title>', ' ').replace('\\n', ' ') #replace the title tag with either title or top to test different query sections\n",
    "            \n",
    "            temptxt += (\" \" +str(top.find('desc')).replace('<desc>', ' ').replace('</desc>', ' ').replace('\\n', ' ')) #Uncomment to do both title and description\n",
    "            temptxt = temptxt.lower()\n",
    "            temptxt = temptxt.translate(str.maketrans(\"'\", \" \")) #Remove apostrophes\n",
    "            temptxt = temptxt.translate(str.maketrans(\"\", \"\", string.punctuation)) #Remove punctuation\n",
    "            temptxt = temptxt.translate(str.maketrans(string.digits, \" \" * len(string.digits))) #Remove digits\n",
    "            # descpoint = temptxt.find('desc')\n",
    "            \n",
    "            # temptxt = temptxt[0:descpoint]\n",
    "            list_of_words = temptxt.split()\n",
    "        \n",
    "            temptxt = [word for word in list_of_words if (word not in stop_words and word not in ['narr', 'desc', 'narrdesc'])] \n",
    "            \n",
    "            token_tags = nltk.pos_tag(temptxt) #looks like [('word', 'POS'), ('word', 'POS'), ...]\n",
    "            token_tags = [word for word in token_tags if word[1][0:2] in pos_tag_map] #remove words that don't have a pos tag in the map\n",
    "            # for item in token_tags:\n",
    "            #     print(wn.synsets(item[0], pos_tag_map[item[1][0:2]]))\n",
    "            \n",
    "            # for i in range(len(token_tags)):\n",
    "            #     token_tags[i] = pos_tag_map[token_tags[i][1][0:2]][0]\n",
    "            expended_tokens = expand_tokens(token_tags)\n",
    "            \n",
    "\n",
    "            \n",
    "            porter = ps.PorterStemmer()\n",
    "            temptxt = [porter.stem(word, 0, len(word)-1) for word in temptxt]\n",
    "\n",
    "\n",
    "            listtxt = \" \".join(temptxt)\n",
    "\n",
    "            # Stem the expanded_tokens\n",
    "            expanded_tokens = [porter.stem(word, 0, len(word)-1) for word in expended_tokens]\n",
    "\n",
    "            #remove duplicates from expanded tokens\n",
    "            expanded_tokens = list(set(expanded_tokens))\n",
    "            \n",
    "            \n",
    "            bert_queries.append(listtxt)\n",
    "            \n",
    "            queries.update({num: temptxt}) #We cannot check the length of the list of words because we don't know how many words are in the stop words list\n",
    "            expandos.update({num: expanded_tokens})\n",
    "\n",
    "    return queries, expandos, bert_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 1/322\n",
      "Progress: 2/322\n",
      "Progress: 3/322\n",
      "Progress: 4/322\n",
      "Progress: 5/322\n",
      "Progress: 6/322\n",
      "Progress: 7/322\n",
      "Progress: 8/322\n",
      "Progress: 9/322\n",
      "Progress: 10/322\n",
      "Progress: 11/322\n",
      "Progress: 12/322\n",
      "Progress: 13/322\n",
      "Progress: 14/322\n",
      "Progress: 15/322\n",
      "Progress: 16/322\n",
      "Progress: 17/322\n",
      "Progress: 18/322\n",
      "Progress: 19/322\n",
      "Progress: 20/322\n",
      "Progress: 21/322\n",
      "Progress: 22/322\n",
      "Progress: 23/322\n",
      "Progress: 24/322\n",
      "Progress: 25/322\n",
      "Progress: 26/322\n",
      "Progress: 27/322\n",
      "Progress: 28/322\n",
      "Progress: 29/322\n",
      "Progress: 30/322\n",
      "Progress: 31/322\n",
      "Progress: 32/322\n",
      "Progress: 33/322\n",
      "Progress: 34/322\n",
      "Progress: 35/322\n",
      "Progress: 36/322\n",
      "Progress: 37/322\n",
      "Progress: 38/322\n",
      "Progress: 39/322\n",
      "Progress: 40/322\n",
      "Progress: 41/322\n",
      "Progress: 42/322\n",
      "Progress: 43/322\n",
      "Progress: 44/322\n",
      "Progress: 45/322\n",
      "Progress: 46/322\n",
      "Progress: 47/322\n",
      "Progress: 48/322\n",
      "Progress: 49/322\n",
      "Progress: 50/322\n",
      "Progress: 51/322\n",
      "Progress: 52/322\n",
      "Progress: 53/322\n",
      "Progress: 54/322\n",
      "Progress: 55/322\n",
      "Progress: 56/322\n",
      "Progress: 57/322\n",
      "Progress: 58/322\n",
      "Progress: 59/322\n",
      "Progress: 60/322\n",
      "Progress: 61/322\n",
      "Progress: 62/322\n",
      "Progress: 63/322\n",
      "Progress: 64/322\n",
      "Progress: 65/322\n",
      "Progress: 66/322\n",
      "Progress: 67/322\n",
      "Progress: 68/322\n",
      "Progress: 69/322\n",
      "Progress: 70/322\n",
      "Progress: 71/322\n",
      "Progress: 72/322\n",
      "Progress: 73/322\n",
      "Progress: 74/322\n",
      "Progress: 75/322\n",
      "Progress: 76/322\n",
      "Progress: 77/322\n",
      "Progress: 78/322\n",
      "Progress: 79/322\n",
      "Progress: 80/322\n",
      "Progress: 81/322\n",
      "Progress: 82/322\n",
      "Progress: 83/322\n",
      "Progress: 84/322\n",
      "Progress: 85/322\n",
      "Progress: 86/322\n",
      "Progress: 87/322\n",
      "Progress: 88/322\n",
      "Progress: 89/322\n",
      "Progress: 90/322\n",
      "Progress: 91/322\n",
      "Progress: 92/322\n",
      "Progress: 93/322\n",
      "Progress: 94/322\n",
      "Progress: 95/322\n",
      "Progress: 96/322\n",
      "Progress: 97/322\n",
      "Progress: 98/322\n",
      "Progress: 99/322\n",
      "Progress: 100/322\n",
      "Progress: 101/322\n",
      "Progress: 102/322\n",
      "Progress: 103/322\n",
      "Progress: 104/322\n",
      "Progress: 105/322\n",
      "Progress: 106/322\n",
      "Progress: 107/322\n",
      "Progress: 108/322\n",
      "Progress: 109/322\n",
      "Progress: 110/322\n",
      "Progress: 111/322\n",
      "Progress: 112/322\n",
      "Progress: 113/322\n",
      "Progress: 114/322\n",
      "Progress: 115/322\n",
      "Progress: 116/322\n",
      "Progress: 117/322\n",
      "Progress: 118/322\n",
      "Progress: 119/322\n",
      "Progress: 120/322\n",
      "Progress: 121/322\n",
      "Progress: 122/322\n",
      "Progress: 123/322\n",
      "Progress: 124/322\n",
      "Progress: 125/322\n",
      "Progress: 126/322\n",
      "Progress: 127/322\n",
      "Progress: 128/322\n",
      "Progress: 129/322\n",
      "Progress: 130/322\n",
      "Progress: 131/322\n",
      "Progress: 132/322\n",
      "Progress: 133/322\n",
      "Progress: 134/322\n",
      "Progress: 135/322\n",
      "Progress: 136/322\n",
      "Progress: 137/322\n",
      "Progress: 138/322\n",
      "Progress: 139/322\n",
      "Progress: 140/322\n",
      "Progress: 141/322\n",
      "Progress: 142/322\n",
      "Progress: 143/322\n",
      "Progress: 144/322\n",
      "Progress: 145/322\n",
      "Progress: 146/322\n",
      "Progress: 147/322\n",
      "Progress: 148/322\n",
      "Progress: 149/322\n",
      "Progress: 150/322\n",
      "Progress: 151/322\n",
      "Progress: 152/322\n",
      "Progress: 153/322\n",
      "Progress: 154/322\n",
      "Progress: 155/322\n",
      "Progress: 156/322\n",
      "Progress: 157/322\n",
      "Progress: 158/322\n",
      "Progress: 159/322\n",
      "Progress: 160/322\n",
      "Progress: 161/322\n",
      "Progress: 162/322\n",
      "Progress: 163/322\n",
      "Progress: 164/322\n",
      "Progress: 165/322\n",
      "Progress: 166/322\n",
      "Progress: 167/322\n",
      "Progress: 168/322\n",
      "Progress: 169/322\n",
      "Progress: 170/322\n",
      "Progress: 171/322\n",
      "Progress: 172/322\n",
      "Progress: 173/322\n",
      "Progress: 174/322\n",
      "Progress: 175/322\n",
      "Progress: 176/322\n",
      "Progress: 177/322\n",
      "Progress: 178/322\n",
      "Progress: 179/322\n",
      "Progress: 180/322\n",
      "Progress: 181/322\n",
      "Progress: 182/322\n",
      "Progress: 183/322\n",
      "Progress: 184/322\n",
      "Progress: 185/322\n",
      "Progress: 186/322\n",
      "Progress: 187/322\n",
      "Progress: 188/322\n",
      "Progress: 189/322\n",
      "Progress: 190/322\n",
      "Progress: 191/322\n",
      "Progress: 192/322\n",
      "Progress: 193/322\n",
      "Progress: 194/322\n",
      "Progress: 195/322\n",
      "Progress: 196/322\n",
      "Progress: 197/322\n",
      "Progress: 198/322\n",
      "Progress: 199/322\n",
      "Progress: 200/322\n",
      "Progress: 201/322\n",
      "Progress: 202/322\n",
      "Progress: 203/322\n",
      "Progress: 204/322\n",
      "Progress: 205/322\n",
      "Progress: 206/322\n",
      "Progress: 207/322\n",
      "Progress: 208/322\n",
      "Progress: 209/322\n",
      "Progress: 210/322\n",
      "Progress: 211/322\n",
      "Progress: 212/322\n",
      "Progress: 213/322\n",
      "Progress: 214/322\n",
      "Progress: 215/322\n",
      "Progress: 216/322\n",
      "Progress: 217/322\n",
      "Progress: 218/322\n",
      "Progress: 219/322\n",
      "Progress: 220/322\n",
      "Progress: 221/322\n",
      "Progress: 222/322\n",
      "Progress: 223/322\n",
      "Progress: 224/322\n",
      "Progress: 225/322\n",
      "Progress: 226/322\n",
      "Progress: 227/322\n",
      "Progress: 228/322\n",
      "Progress: 229/322\n",
      "Progress: 230/322\n",
      "Progress: 231/322\n",
      "Progress: 232/322\n",
      "Progress: 233/322\n",
      "Progress: 234/322\n",
      "Progress: 235/322\n",
      "Progress: 236/322\n",
      "Progress: 237/322\n",
      "Progress: 238/322\n",
      "Progress: 239/322\n",
      "Progress: 240/322\n",
      "Progress: 241/322\n",
      "Progress: 242/322\n",
      "Progress: 243/322\n",
      "Progress: 244/322\n",
      "Progress: 245/322\n",
      "Progress: 246/322\n",
      "Progress: 247/322\n",
      "Progress: 248/322\n",
      "Progress: 249/322\n",
      "Progress: 250/322\n",
      "Progress: 251/322\n",
      "Progress: 252/322\n",
      "Progress: 253/322\n",
      "Progress: 254/322\n",
      "Progress: 255/322\n",
      "Progress: 256/322\n",
      "Progress: 257/322\n",
      "Progress: 258/322\n",
      "Progress: 259/322\n",
      "Progress: 260/322\n",
      "Progress: 261/322\n",
      "Progress: 262/322\n",
      "Progress: 263/322\n",
      "Progress: 264/322\n",
      "Progress: 265/322\n",
      "Progress: 266/322\n",
      "Progress: 267/322\n",
      "Progress: 268/322\n",
      "Progress: 269/322\n",
      "Progress: 270/322\n",
      "Progress: 271/322\n",
      "Progress: 272/322\n",
      "Progress: 273/322\n",
      "Progress: 274/322\n",
      "Progress: 275/322\n",
      "Progress: 276/322\n",
      "Progress: 277/322\n",
      "Progress: 278/322\n",
      "Progress: 279/322\n",
      "Progress: 280/322\n",
      "Progress: 281/322\n",
      "Progress: 282/322\n",
      "Progress: 283/322\n",
      "Progress: 284/322\n",
      "Progress: 285/322\n",
      "Progress: 286/322\n",
      "Progress: 287/322\n",
      "Progress: 288/322\n",
      "Progress: 289/322\n",
      "Progress: 290/322\n",
      "Progress: 291/322\n",
      "Progress: 292/322\n",
      "Progress: 293/322\n",
      "Progress: 294/322\n",
      "Progress: 295/322\n",
      "Progress: 296/322\n",
      "Progress: 297/322\n",
      "Progress: 298/322\n",
      "Progress: 299/322\n",
      "Progress: 300/322\n",
      "Progress: 301/322\n",
      "Progress: 302/322\n",
      "Progress: 303/322\n",
      "Progress: 304/322\n",
      "Progress: 305/322\n",
      "Progress: 306/322\n",
      "Progress: 307/322\n",
      "Progress: 308/322\n",
      "Progress: 309/322\n",
      "Progress: 310/322\n",
      "Progress: 311/322\n",
      "Progress: 312/322\n",
      "Progress: 313/322\n",
      "Progress: 314/322\n",
      "Progress: 315/322\n",
      "Progress: 316/322\n",
      "Progress: 317/322\n",
      "Progress: 318/322\n",
      "Progress: 319/322\n",
      "Progress: 320/322\n",
      "Progress: 321/322\n",
      "Progress: 322/322\n",
      "vocabulary length:  151729\n",
      "files length:  79923\n"
     ]
    }
   ],
   "source": [
    "files, vocabulary, bert_files, bert_docnos = collect_info(coll_files, stop_words)\n",
    "number_of_documents = len(files)\n",
    "print(\"vocabulary length: \" , len(vocabulary))\n",
    "print(\"files length: \" , len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries, expanded_queries, bert_queries = collect_queries()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BERT_similarities(documents, queries, docnos):\n",
    "    #Iterate over queries and documents, encode one query and one document at a time using BERT\n",
    "    model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "    similarities = {i:{} for i in range(len(queries))}\n",
    "    for i in range(len(queries)):\n",
    "        for j in range(len(documents)):\n",
    "            #If the document contains 2 words in the query, compute the similarity otherwise, skip it\n",
    "            if any(word in documents[j] for word in queries[i]):\n",
    "                #Join the query and doc into one list\n",
    "                combined = [queries[i], documents[j]]\n",
    "                #Encode the query and document\n",
    "                embedding = model.encode(combined)\n",
    "                #Compute the cosine similarity between the query and document\n",
    "                similarity = cosine_similarity(embedding[0].reshape(1,-1), embedding[1].reshape(1,-1))\n",
    "                #Store the similarity in the similarities dictionary\n",
    "                similarities[i][docnos[j]] = similarity[0][0]\n",
    "                if j % 100 == 0:\n",
    "                    print(\"similarity prog: \", j, \" of \", len(documents))\n",
    "        print(\"similarity prog: \", i, \" of \", len(queries))\n",
    "    return similarities\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_encode_similarities(documents, queries, docnos):\n",
    "    combined = queries+ documents\n",
    "    query_ids = [str(i) for i in range(len(queries))]\n",
    "    combined_docnos = query_ids+docnos\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    embeddings = model.encode(combined, show_progress_bar=True)\n",
    "    similarities = cosine_similarity(embeddings)\n",
    "    similarities_sorted = similarities.argsort()\n",
    "\n",
    "    #Create a dictionary of dictionaries to store the similarities with the docnos as keys for each sub dictionary\n",
    "    print(combined_docnos)\n",
    "    score_dict = {i:{} for i in combined_docnos}\n",
    "    # for index,array in enumerate(similarities_sorted):\n",
    "    #     id_2 = array[-2]\n",
    "    #     score = similarities[index][id_2]\n",
    "    #     score_dict[combined_docnos[index]][combined_docnos[id_2]] = score\n",
    "\n",
    "    id_1 = []\n",
    "    id_2 = []\n",
    "    score = []\n",
    "    for index,array in enumerate(similarities_sorted):\n",
    "        print(array)\n",
    "        id_1.append(combined_docnos[index])\n",
    "        id_2.append(combined_docnos[array[-2]])\n",
    "        score.append(similarities[index][array[-2]])\n",
    "\n",
    "    # index_df = pd.DataFrame(score_dict)\n",
    "    index_df = pd.DataFrame({'id_1' : id_1,\n",
    "                          'id_2' : id_2,\n",
    "                          'score' : score})\n",
    "    return score_dict, index_df\n",
    "\n",
    "\n",
    "    \n",
    "    print(\"similarity prog: \", i, \" of \", len(queries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def STS_similarity(documents, queries, docnos):\n",
    "    model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "    embeddings1 = model.encode(queries, convert_to_tensor=True)\n",
    "    embeddings2 = model.encode(documents, convert_to_tensor=True)\n",
    "    cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
    "    #Output the pairs with their score\n",
    "    return cosine_scores\n",
    "    for i in range(len(docnos)):\n",
    "        print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(docnos[i], i, cosine_scores[i][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mine_paraphrases(documents, queries, docnos):\n",
    "    combined = queries+ documents\n",
    "    query_ids = [str(i) for i in range(len(queries))]\n",
    "    combined_docnos = query_ids+docnos\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    paraphrases = util.paraphrase_mining(model, combined, show_progress_bar=True)\n",
    "    for paraphrase in paraphrases[0:10]:\n",
    "        score, i, j = paraphrase\n",
    "        print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(combined_docnos[i], combined_docnos[j], score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', 'AP880212-0001', 'AP880212-0002', 'AP880212-0003']\n",
      "[4 5 3 1 2 0]\n",
      "[4 5 3 0 2 1]\n",
      "[4 3 5 0 1 2]\n",
      "[4 2 1 0 5 3]\n",
      "[2 0 1 3 5 4]\n",
      "[4 2 0 1 3 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "simiarities, df = full_encode_similarities(bert_files[0:3], bert_queries[0:3], bert_docnos[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/8 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\adamj\\Documents\\GitHub\\CSI4107-Information Retrieval System\\BERT_System.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/adamj/Documents/GitHub/CSI4107-Information%20Retrieval%20System/BERT_System.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m beepis \u001b[39m=\u001b[39m mine_paraphrases(bert_files[\u001b[39m0\u001b[39;49m:\u001b[39m200\u001b[39;49m], bert_queries[\u001b[39m0\u001b[39;49m:\u001b[39m200\u001b[39;49m], bert_docnos[\u001b[39m0\u001b[39;49m:\u001b[39m200\u001b[39;49m])\n",
      "\u001b[1;32mc:\\Users\\adamj\\Documents\\GitHub\\CSI4107-Information Retrieval System\\BERT_System.ipynb Cell 11\u001b[0m in \u001b[0;36mmine_paraphrases\u001b[1;34m(documents, queries, docnos)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adamj/Documents/GitHub/CSI4107-Information%20Retrieval%20System/BERT_System.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m combined_docnos \u001b[39m=\u001b[39m query_ids\u001b[39m+\u001b[39mdocnos\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adamj/Documents/GitHub/CSI4107-Information%20Retrieval%20System/BERT_System.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model \u001b[39m=\u001b[39m SentenceTransformer(\u001b[39m'\u001b[39m\u001b[39mall-MiniLM-L6-v2\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/adamj/Documents/GitHub/CSI4107-Information%20Retrieval%20System/BERT_System.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m paraphrases \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39;49mparaphrase_mining(model, combined, show_progress_bar\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adamj/Documents/GitHub/CSI4107-Information%20Retrieval%20System/BERT_System.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m paraphrase \u001b[39min\u001b[39;00m paraphrases[\u001b[39m0\u001b[39m:\u001b[39m10\u001b[39m]:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adamj/Documents/GitHub/CSI4107-Information%20Retrieval%20System/BERT_System.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     score, i, j \u001b[39m=\u001b[39m paraphrase\n",
      "File \u001b[1;32mc:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\util.py:130\u001b[0m, in \u001b[0;36mparaphrase_mining\u001b[1;34m(model, sentences, show_progress_bar, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[39mGiven a list of sentences / texts, this function performs paraphrase mining. It compares all sentences against all\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[39mother sentences and returns a list with the pairs that have the highest cosine similarity score.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[39m:return: Returns a list of triplets with the format [score, id1, id2]\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[39m# Compute embedding for the sentences\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m embeddings \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mencode(sentences, show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar, batch_size\u001b[39m=\u001b[39;49mbatch_size, convert_to_tensor\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    132\u001b[0m \u001b[39mreturn\u001b[39;00m paraphrase_mining_embeddings(embeddings, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:165\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[1;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[0;32m    162\u001b[0m features \u001b[39m=\u001b[39m batch_to_device(features, device)\n\u001b[0;32m    164\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 165\u001b[0m     out_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(features)\n\u001b[0;32m    167\u001b[0m     \u001b[39mif\u001b[39;00m output_value \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    168\u001b[0m         embeddings \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py:66\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m features:\n\u001b[0;32m     64\u001b[0m     trans_features[\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m features[\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> 66\u001b[0m output_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrans_features, return_dict\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     67\u001b[0m output_tokens \u001b[39m=\u001b[39m output_states[\u001b[39m0\u001b[39m]\n\u001b[0;32m     69\u001b[0m features\u001b[39m.\u001b[39mupdate({\u001b[39m'\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m'\u001b[39m: output_tokens, \u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m: features[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]})\n",
      "File \u001b[1;32mc:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1020\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1011\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   1013\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[0;32m   1014\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[0;32m   1015\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   1019\u001b[0m )\n\u001b[1;32m-> 1020\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[0;32m   1021\u001b[0m     embedding_output,\n\u001b[0;32m   1022\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[0;32m   1023\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1024\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m   1025\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[0;32m   1026\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m   1027\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1028\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1029\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1030\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1031\u001b[0m )\n\u001b[0;32m   1032\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1033\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:610\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    601\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m    602\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    603\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    607\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    608\u001b[0m     )\n\u001b[0;32m    609\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 610\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m    611\u001b[0m         hidden_states,\n\u001b[0;32m    612\u001b[0m         attention_mask,\n\u001b[0;32m    613\u001b[0m         layer_head_mask,\n\u001b[0;32m    614\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    615\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    616\u001b[0m         past_key_value,\n\u001b[0;32m    617\u001b[0m         output_attentions,\n\u001b[0;32m    618\u001b[0m     )\n\u001b[0;32m    620\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    621\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:495\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    484\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    485\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    492\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m    493\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    494\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[0;32m    496\u001b[0m         hidden_states,\n\u001b[0;32m    497\u001b[0m         attention_mask,\n\u001b[0;32m    498\u001b[0m         head_mask,\n\u001b[0;32m    499\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    500\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[0;32m    501\u001b[0m     )\n\u001b[0;32m    502\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    504\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:434\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    416\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    417\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    423\u001b[0m     output_attentions: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    424\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m    425\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself(\n\u001b[0;32m    426\u001b[0m         hidden_states,\n\u001b[0;32m    427\u001b[0m         attention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    432\u001b[0m         output_attentions,\n\u001b[0;32m    433\u001b[0m     )\n\u001b[1;32m--> 434\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput(self_outputs[\u001b[39m0\u001b[39;49m], hidden_states)\n\u001b[0;32m    435\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n\u001b[0;32m    436\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:386\u001b[0m, in \u001b[0;36mBertSelfOutput.forward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    384\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdense(hidden_states)\n\u001b[0;32m    385\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m--> 386\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mLayerNorm(hidden_states \u001b[39m+\u001b[39;49m input_tensor)\n\u001b[0;32m    387\u001b[0m \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32mc:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1494\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1491\u001b[0m             tracing_state\u001b[39m.\u001b[39mpop_scope()\n\u001b[0;32m   1492\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[1;32m-> 1494\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_impl\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1495\u001b[0m     forward_call \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_get_tracing_state() \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward)\n\u001b[0;32m   1496\u001b[0m     \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m     \u001b[39m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "beepis = mine_paraphrases(bert_files[0:200], bert_queries[0:200], bert_docnos[0:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "borgipis = STS_similarity(bert_files[0:1000], bert_queries[0], bert_docnos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to Tensor.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\adamj\\Documents\\GitHub\\CSI4107-Information Retrieval System\\BERT_System.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adamj/Documents/GitHub/CSI4107-Information%20Retrieval%20System/BERT_System.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m borgipis\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adamj/Documents/GitHub/CSI4107-Information%20Retrieval%20System/BERT_System.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(bert_docnos)):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/adamj/Documents/GitHub/CSI4107-Information%20Retrieval%20System/BERT_System.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m \u001b[39;49m\u001b[39m\\t\u001b[39;49;00m\u001b[39m\\t\u001b[39;49;00m\u001b[39m \u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m \u001b[39;49m\u001b[39m\\t\u001b[39;49;00m\u001b[39m\\t\u001b[39;49;00m\u001b[39m Score: \u001b[39;49m\u001b[39m{:.4f}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mformat(bert_docnos[i], i, borgipis[i]))\n",
      "File \u001b[1;32mc:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:873\u001b[0m, in \u001b[0;36mTensor.__format__\u001b[1;34m(self, format_spec)\u001b[0m\n\u001b[0;32m    871\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_meta \u001b[39mand\u001b[39;00m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39mis\u001b[39;00m Tensor:\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem()\u001b[39m.\u001b[39m\u001b[39m__format__\u001b[39m(format_spec)\n\u001b[1;32m--> 873\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__format__\u001b[39;49m(\u001b[39mself\u001b[39;49m, format_spec)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported format string passed to Tensor.__format__"
     ]
    }
   ],
   "source": [
    "borgipis\n",
    "for i in range(len(bert_docnos)):\n",
    "        print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(bert_docnos[i], i, borgipis[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(bert_embeddings)\n",
    "similarities = cosine_similarity(bert_embeddings)\n",
    "similarities_sorted = similarities.argsort()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
