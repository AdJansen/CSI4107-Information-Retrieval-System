{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement an Information Retrieval (IR) system based on the vector space model, for a collection of documents\n",
    "#For weighting, you can use the tf-idf weighting scheme (wij = tfij∙idfi)\n",
    "#For each query, your system will produce a ranked list of documents, starting with the most similar to the query and ending with the least similar. For the query terms you can use a modified tf-idf weighting scheme wiq = (0.5 + 0.5 tfiq)∙idfi\n",
    "#For the ranking, you can use the cosine similarity measure\n",
    "import time\n",
    "import Porter_Stemming as ps\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import string\n",
    "import csv\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1 Preprocessing\n",
    "#Input: Documents that are read one by one from the collection\n",
    "#Output: Tokens to be added to the index (vocabulary)\n",
    "#Get Start time \n",
    "start_time = time.time()\n",
    "\n",
    "coll_files = [f for f in os.listdir(r\"./coll/\") if os.path.isfile(os.path.join(r\"./coll/\", f))]\n",
    "stop_words = open(r\"./stopwords.txt\", \"r\").read().split()\n",
    "\n",
    "def collect_info(coll_files, stop_words):\n",
    "    files = [] \n",
    "    list_of_words = [] \n",
    "    vocabulary = set([]) #We use a set because we don't want to have duplicates in the vocabulary\n",
    "    \n",
    "    for file in coll_files:\n",
    "        with open(r\"./coll/\" + file, \"r\") as f:\n",
    "            soup = BeautifulSoup(f, 'lxml') \n",
    "            \n",
    "            for doc in soup.find_all('doc'):\n",
    "                docno = doc.find_all('docno')[0].text.strip()\n",
    "\n",
    "                temptxt = str(doc.find('text')).replace('<text>', ' ').replace('</text>', ' ').replace('\\n', ' ')\n",
    "                temptxt = temptxt.lower()\n",
    "                temptxt = temptxt.translate(str.maketrans(string.punctuation, \" \" * len(string.punctuation)))\n",
    "                temptxt = temptxt.translate(str.maketrans(string.digits, \" \" * len(string.digits)))\n",
    "                \n",
    "                list_of_words = temptxt.split()\n",
    "                \n",
    "                porter = ps.PorterStemmer()\n",
    "                list_of_words = [porter.stem(word, 0, len(word)-1) for word in list_of_words]\n",
    "                \n",
    "                temptxt = list(set(list_of_words) - set(stop_words))\n",
    "                \n",
    "                vocabulary.update(set(temptxt))\n",
    "                files.append({docno: temptxt}) #We cannot check the length of the list of words because we don't know how many words are in the stop words list\n",
    "    return files, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inverted_index(files, vocabulary):\n",
    "    inverted_index = {i:[] for i in vocabulary}\n",
    "    count = 0\n",
    "    csv_columns = ['word', 'documents']\n",
    "    for file in files: #key is the docno, value is the list of words\n",
    "        count += 1\n",
    "        key, value = list(file.items())[0]\n",
    "        for word in value: #if the word is in the document, then we add that document to the inverted index\n",
    "                inverted_index[word].append(key)\n",
    "        if count % 100 == 0:\n",
    "            print(\" count: \", count)\n",
    "\n",
    "    #Use Pandas to send inverted index to csv file\n",
    "    count = 0\n",
    "    csv_file = r\"./inverted_index.csv\"\n",
    "    try:\n",
    "        with open(csv_file, 'w') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(csv_columns)\n",
    "            for data in inverted_index:\n",
    "                count += 1\n",
    "                writer.writerow([data, inverted_index[data]])\n",
    "                if count % 100 == 0:\n",
    "                    print(\" count: \", count)\n",
    "    except IOError:\n",
    "        print(\"I/O error\")\n",
    "\n",
    "    return inverted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_queries():\n",
    "    queries = {}\n",
    "    list_of_words = [] \n",
    "    \n",
    "    \n",
    "    with open(r\"./topics1-50.txt\", \"r\") as f:\n",
    "        soup = BeautifulSoup(f, 'lxml') \n",
    "        \n",
    "        for top in soup.find_all('top'):\n",
    "            num = top.find_all('num')[0].text.strip()[0:2].strip() #this is a stupid way to do it, don't follow my example \n",
    "\n",
    "            temptxt = str(top.find('title')).replace('<title>', ' ').replace('</title>', ' ').replace('\\n', ' ') #replace the title tag with either title or top to test different query sections\n",
    "            temptxt = temptxt.lower()\n",
    "            temptxt = temptxt.translate(str.maketrans(string.punctuation, \" \" * len(string.punctuation)))\n",
    "            temptxt = temptxt.translate(str.maketrans(string.digits, \" \" * len(string.digits)))\n",
    "            \n",
    "            list_of_words = temptxt.split()\n",
    "            \n",
    "            porter = ps.PorterStemmer()\n",
    "            list_of_words = [porter.stem(word, 0, len(word)-1) for word in list_of_words]\n",
    "            \n",
    "            temptxt = list(set(list_of_words) - set(stop_words))\n",
    "            \n",
    "            queries.update({num: temptxt}) #We cannot check the length of the list of words because we don't know how many words are in the stop words list\n",
    "\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(query, document):\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary length:  116854\n",
      "files length:  79923\n"
     ]
    }
   ],
   "source": [
    "files, vocabulary = collect_info(coll_files, stop_words)\n",
    "\n",
    "print(\"vocabulary length: \" , len(vocabulary))\n",
    "print(\"files length: \" , len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = create_inverted_index(files, vocabulary)\n",
    "print(inverted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = collect_queries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AP880212-0002': ['big',\n",
       "  'aid',\n",
       "  'field',\n",
       "  'loser',\n",
       "  'vulner',\n",
       "  'probabl',\n",
       "  'huge',\n",
       "  'sharpli',\n",
       "  'nbc',\n",
       "  'continu',\n",
       "  'simon',\n",
       "  'iowa',\n",
       "  'thei',\n",
       "  'ago',\n",
       "  'dole',\n",
       "  'hi',\n",
       "  'arizona',\n",
       "  'survei',\n",
       "  'street',\n",
       "  'candidaci',\n",
       "  'kemp',\n",
       "  'washington',\n",
       "  'turn',\n",
       "  'kansa',\n",
       "  'drop',\n",
       "  'margin',\n",
       "  'precinct',\n",
       "  'mondai',\n",
       "  'essenti',\n",
       "  'finish',\n",
       "  'slip',\n",
       "  'orren',\n",
       "  'mix',\n",
       "  'lead',\n",
       "  'amount',\n",
       "  'top',\n",
       "  'battl',\n",
       "  'place',\n",
       "  'dai',\n",
       "  'alderman',\n",
       "  'novemb',\n",
       "  'boost',\n",
       "  'pat',\n",
       "  'illinoi',\n",
       "  'peopl',\n",
       "  'bruce',\n",
       "  'babbitt',\n",
       "  'abc',\n",
       "  'doubt',\n",
       "  'put',\n",
       "  'dukaki',\n",
       "  'vote',\n",
       "  'matter',\n",
       "  'leav',\n",
       "  'chief',\n",
       "  'rival',\n",
       "  'steadi',\n",
       "  'voter',\n",
       "  'surpris',\n",
       "  'ha',\n",
       "  'poll',\n",
       "  'georg',\n",
       "  'percentag',\n",
       "  'gari',\n",
       "  'rep',\n",
       "  'thursdai',\n",
       "  'fall',\n",
       "  'gop',\n",
       "  'error',\n",
       "  'bob',\n",
       "  'hampshir',\n",
       "  'final',\n",
       "  'kick',\n",
       "  'republican',\n",
       "  'question',\n",
       "  'late',\n",
       "  'york',\n",
       "  'movement',\n",
       "  'wa',\n",
       "  'strong',\n",
       "  'win',\n",
       "  'democrat',\n",
       "  'heat',\n",
       "  'command',\n",
       "  'anoth',\n",
       "  'bush',\n",
       "  'vice',\n",
       "  'post',\n",
       "  'earlier',\n",
       "  'primari',\n",
       "  'challeng',\n",
       "  'expect',\n",
       "  'fourth',\n",
       "  'spread',\n",
       "  'lost',\n",
       "  'backer',\n",
       "  'cb',\n",
       "  'transform',\n",
       "  'move',\n",
       "  'month',\n",
       "  'gainer',\n",
       "  'tv',\n",
       "  'dead',\n",
       "  'boston',\n",
       "  'bottom',\n",
       "  'missouri',\n",
       "  'support',\n",
       "  'gov',\n",
       "  'ar',\n",
       "  'wrc',\n",
       "  'paul',\n",
       "  'michael',\n",
       "  'fell',\n",
       "  'risen',\n",
       "  'morin',\n",
       "  'pack',\n",
       "  'look',\n",
       "  'arous',\n",
       "  'herald',\n",
       "  'strongli',\n",
       "  'point',\n",
       "  'jeff',\n",
       "  'told',\n",
       "  'caucus',\n",
       "  'richard',\n",
       "  'appear',\n",
       "  'thi',\n",
       "  'singl',\n",
       "  'hart',\n",
       "  'analyst',\n",
       "  'nation',\n",
       "  'indic',\n",
       "  'percent',\n",
       "  'unansw',\n",
       "  'effect',\n",
       "  'globe',\n",
       "  'rippl',\n",
       "  'jack',\n",
       "  'winner',\n",
       "  'result',\n",
       "  'robertson',\n",
       "  'pollster',\n",
       "  'poor',\n",
       "  'held',\n",
       "  'befor',\n",
       "  'wbz',\n",
       "  'ground',\n",
       "  'presid',\n",
       "  'gain',\n",
       "  'direct',\n",
       "  'massachusett',\n",
       "  'colorado',\n",
       "  'diminish',\n",
       "  'crack',\n",
       "  'sort',\n",
       "  'maintain',\n",
       "  'wall',\n",
       "  'sinc',\n",
       "  'meanwhil',\n",
       "  'januari',\n",
       "  'veri',\n",
       "  'damag',\n",
       "  'howev',\n",
       "  'despit',\n",
       "  'digit',\n",
       "  'gephardt',\n",
       "  'mai',\n",
       "  'race',\n",
       "  'reluct',\n",
       "  'director',\n",
       "  'sen']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\adamj\\Documents\\GitHub\\CSI4107-Information Retrieval System\\IR_System.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adamj/Documents/GitHub/CSI4107-Information%20Retrieval%20System/IR_System.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m51\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adamj/Documents/GitHub/CSI4107-Information%20Retrieval%20System/IR_System.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(files)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/adamj/Documents/GitHub/CSI4107-Information%20Retrieval%20System/IR_System.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         scores\u001b[39m.\u001b[39mappend(compute_cosine_similarity(queries[\u001b[39m'\u001b[39;49m\u001b[39m3\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39mlist\u001b[39;49m(files[i]\u001b[39m.\u001b[39;49mvalues())[\u001b[39m0\u001b[39;49m]))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adamj/Documents/GitHub/CSI4107-Information%20Retrieval%20System/IR_System.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(compute_cosine_similarity(\u001b[39m\"\u001b[39m\u001b[39mI love horror movies\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mLights out is a horror movie\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adamj/Documents/GitHub/CSI4107-Information%20Retrieval%20System/IR_System.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mmax\u001b[39m(scores))\n",
      "\u001b[1;32mc:\\Users\\adamj\\Documents\\GitHub\\CSI4107-Information Retrieval System\\IR_System.ipynb Cell 10\u001b[0m in \u001b[0;36mcompute_cosine_similarity\u001b[1;34m(query, document)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adamj/Documents/GitHub/CSI4107-Information%20Retrieval%20System/IR_System.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_cosine_similarity\u001b[39m(query, document):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adamj/Documents/GitHub/CSI4107-Information%20Retrieval%20System/IR_System.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m# cosine similarity = A.B / ||A|| * ||B||\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adamj/Documents/GitHub/CSI4107-Information%20Retrieval%20System/IR_System.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m# A = query\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/adamj/Documents/GitHub/CSI4107-Information%20Retrieval%20System/IR_System.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39m# print(\"union: \", len(set(query).union(set(document))))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/adamj/Documents/GitHub/CSI4107-Information%20Retrieval%20System/IR_System.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39m# print(\"intersection/union: \", len(set(query).intersection(set(document)))/len(set(query).union(set(document))))\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/adamj/Documents/GitHub/CSI4107-Information%20Retrieval%20System/IR_System.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39;49m(\u001b[39mset\u001b[39;49m(query)\u001b[39m.\u001b[39;49mintersection(\u001b[39mset\u001b[39;49m(document)))\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(query)\u001b[39m.\u001b[39munion(\u001b[39mset\u001b[39m(document)))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# print(compute_cosine_similarity(queries['1'], list(files[2].values())[0]))\n",
    "scores = []\n",
    "for t in range(1, 51):\n",
    "    for i in range(len(files)-1):\n",
    "        scores.append(compute_cosine_similarity(queries['3'], list(files[i].values())[0]))\n",
    "    \n",
    "\n",
    "print(max(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\adamj\\Documents\\GitHub\\CSI4107-Information Retrieval System\\IR_System.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/adamj/Documents/GitHub/CSI4107-Information%20Retrieval%20System/IR_System.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(compute_cosine_similarity(\u001b[39m\"\u001b[39;49m\u001b[39mI love horror movies\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mLights out is a horror movie\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "\u001b[1;32mc:\\Users\\adamj\\Documents\\GitHub\\CSI4107-Information Retrieval System\\IR_System.ipynb Cell 11\u001b[0m in \u001b[0;36mcompute_cosine_similarity\u001b[1;34m(query, document)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adamj/Documents/GitHub/CSI4107-Information%20Retrieval%20System/IR_System.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mif\u001b[39;00m word \u001b[39min\u001b[39;00m document:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adamj/Documents/GitHub/CSI4107-Information%20Retrieval%20System/IR_System.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         numerator \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m0.5\u001b[39m \u001b[39m+\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m query[word]) \u001b[39m*\u001b[39m (\u001b[39m0.5\u001b[39m \u001b[39m+\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m document[word]) \u001b[39m*\u001b[39m idf[word]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/adamj/Documents/GitHub/CSI4107-Information%20Retrieval%20System/IR_System.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     denominator1 \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m0.5\u001b[39m \u001b[39m+\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m query[word]) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/adamj/Documents/GitHub/CSI4107-Information%20Retrieval%20System/IR_System.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     denominator2 \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m0.5\u001b[39m \u001b[39m+\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m document[word]) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/adamj/Documents/GitHub/CSI4107-Information%20Retrieval%20System/IR_System.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m denominator \u001b[39m=\u001b[39m (denominator1 \u001b[39m*\u001b[39m denominator2) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m0.5\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "print(compute_cosine_similarity(\"I love horror movies\", \"Lights out is a horror movie\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1230bc2996daf223e6b57a912b6139c94249dacdc4187f83e6f04a96b987e10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
